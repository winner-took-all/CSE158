{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/cui/Projects/PycharmProjects/CSE-158/data/train_Interactions.csv\"\n",
    "file = open(path, 'rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = file.readline()\n",
    "header = header.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file:\n",
    "    fields = line.strip().split(',')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['rating'] = int(d['rating'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userID': 'u79354815', 'bookID': 'b14275065', 'rating': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[d['userID'], d['bookID'], d['rating']] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 190000\n",
    "trainingSet = data[:split]\n",
    "validationSet = [[d[0], d[1], 1] for d in data[split:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u35176258', 'b30592470', 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerBook = defaultdict(set)\n",
    "booksPerUser = defaultdict(set)\n",
    "booksRatingPerUser = defaultdict(dict)\n",
    "bookSets = set()\n",
    "\n",
    "# userIndex[user] = 0\n",
    "userIndex = defaultdict(int)\n",
    "# indexUser[index] = user\n",
    "indexUser = defaultdict(int)\n",
    "# bookIndex[user] = 0\n",
    "bookIndex = defaultdict(int)\n",
    "# indexBook[index] = book\n",
    "indexBook = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in trainingSet:\n",
    "    user, book, rating = d[0], d[1], d[2]\n",
    "    usersPerBook[book].add(user)\n",
    "    booksPerUser[user].add(book)\n",
    "    booksRatingPerUser[user][book] = rating\n",
    "    bookSets.add(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for user in booksPerUser:\n",
    "    userIndex[user] = index\n",
    "    indexUser[index] = user\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for book in usersPerBook:\n",
    "    bookIndex[book] = index\n",
    "    indexBook[index] = book\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookAvgRating = defaultdict(int)\n",
    "bookRatedCount = defaultdict(int)\n",
    "avgRatingPerUser = defaultdict(int)\n",
    "\n",
    "for d in trainingSet:\n",
    "    user, book, rating = d[0], d[1], d[2]\n",
    "    bookAvgRating[book] += rating\n",
    "    avgRatingPerUser[user] += rating\n",
    "    bookRatedCount[book] += 1\n",
    "\n",
    "for book in bookAvgRating:\n",
    "    bookAvgRating[book] = bookAvgRating[book] / bookRatedCount[book]\n",
    "\n",
    "for user in avgRatingPerUser:\n",
    "    avgRatingPerUser[user] = avgRatingPerUser[user] / len(booksPerUser[user])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRating = 0\n",
    "for b in bookAvgRating:\n",
    "    avgRating += bookAvgRating[b]\n",
    "avgRating = avgRating / len(bookAvgRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.813463732600103"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookAvgRating['b14275065']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7169"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bookSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11357"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(booksPerUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 0 data for validation set\n",
    "valid_user = [d[0] for d in validationSet]\n",
    "\n",
    "for user in valid_user:\n",
    "    booksNotReadSet = bookSets - booksPerUser.get(user)\n",
    "    book = random.choice(list(booksNotReadSet))\n",
    "    validationSet.append([user, book, 0])\n",
    "\n",
    "# random.shuffle(validationSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validationSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson(u1, u2):\n",
    "    s1, s2 = booksPerUser[u1], booksPerUser[u2]\n",
    "    items = s1.intersection(s2)\n",
    "    if len(items) == 0:\n",
    "        return 0\n",
    "    \n",
    "    numer, denoml, denomr = 0, 0, 0\n",
    "    \n",
    "    for book in items:\n",
    "        r_u1, r_u1_avg = booksRatingPerUser[u1][book], avgRatingPerUser[u1]\n",
    "        r_u2, r_u2_avg = booksRatingPerUser[u2][book], avgRatingPerUser[u2]\n",
    "        \n",
    "        numer += (r_u1 - r_u1_avg) * (r_u2 - r_u2_avg)\n",
    "        denoml += (r_u1 - r_u1_avg) ** 2\n",
    "        denomr += (r_u2 - r_u2_avg) ** 2\n",
    "\n",
    "    denom = np.sqrt(denoml) * np.sqrt(denomr)\n",
    "    \n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(u1, u2):\n",
    "    s1, s2 = booksPerUser[u1], booksPerUser[u2]\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    \n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_book(b1, b2):\n",
    "    s1, s2 = usersPerBook[b1], usersPerBook[b2]\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    \n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(booksPerUser)\n",
    "num_book = len(usersPerBook)\n",
    "similarityMatrix_user = np.zeros((num, num))\n",
    "similarityMatrix_book = np.zeros((num_book, num_book))\n",
    "\n",
    "for user1 in booksPerUser:\n",
    "    user1_index = userIndex[user1]\n",
    "    \n",
    "    for user2 in booksPerUser:\n",
    "        user2_index = userIndex[user2]\n",
    "        \n",
    "        if user2_index > user1_index:\n",
    "#             similarity = Pearson(user1, user2)\n",
    "            similarity = Jaccard(user1, user2)\n",
    "            similarityMatrix_user[user1_index][user2_index] = similarity\n",
    "            similarityMatrix_user[user2_index][user1_index] = similarity\n",
    "\n",
    "for book1 in usersPerBook:\n",
    "    book1_index = bookIndex[book1]\n",
    "    \n",
    "    for book2 in usersPerBook:\n",
    "        book2_index = bookIndex[book2]\n",
    "        \n",
    "        if book2_index > book1_index:\n",
    "            similarity = Jaccard_book(book1, book2)\n",
    "            similarityMatrix_book[book1_index][book2_index] = similarity\n",
    "            similarityMatrix_book[book2_index][book1_index] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostPopularBooks(threshold):\n",
    "    bookCount = defaultdict(int)\n",
    "    totalRead = 0\n",
    "    threshold = threshold\n",
    "\n",
    "    for d in trainingSet:\n",
    "        bookCount[d[1]] += 1\n",
    "        totalRead += 1\n",
    "\n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalRead * threshold: break\n",
    "            \n",
    "    return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgSimilarity(predictUser, book):\n",
    "    users = usersPerBook[book]\n",
    "    count = 0\n",
    "    avgSimilarity = 0\n",
    "    for user in users:\n",
    "        avgSimilarity += similarityMatrix_user[userIndex[predictUser]][userIndex[user]]\n",
    "        count += 1\n",
    "    \n",
    "    if count == 0:\n",
    "        return 0\n",
    "    \n",
    "    avgSimilarity = avgSimilarity / count\n",
    "    \n",
    "    if math.isnan(avgSimilarity):\n",
    "        return 0\n",
    "\n",
    "    return avgSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookPopularity = defaultdict(int)\n",
    "userActivity = defaultdict(int)\n",
    "for book in usersPerBook:\n",
    "    bookPopularity[book] = len(usersPerBook[book])\n",
    "for user in booksPerUser:\n",
    "    userActivity[user] = len(booksPerUser[user])\n",
    "\n",
    "maxPopu = max([bookPopularity[b] for b in bookPopularity])\n",
    "maxActi = max([userActivity[u] for u in userActivity])\n",
    "    \n",
    "for book in bookPopularity:\n",
    "    bookPopularity[book] = bookPopularity[book] / maxPopu\n",
    "for user in userActivity:\n",
    "    userActivity[user] = userActivity[user] / maxActi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    predictUser, predictBook = datum[0], datum[1]\n",
    "    feat = []\n",
    "    \n",
    "    # average rating of book\n",
    "    feat.append(bookAvgRating[predictBook] - avgRating)\n",
    "    \n",
    "    feat.append(bookPopularity[predictBook])\n",
    "    \n",
    "    feat.append(userActivity[predictUser])\n",
    "    \n",
    "    booksRatedList = booksRatingPerUser[predictUser]\n",
    "    \n",
    "    maxRating = max([b for b in booksRatedList])\n",
    "    minRating = min([b for b in booksRatedList])\n",
    "    \n",
    "    tempSimi = 0\n",
    "    count = 0\n",
    "    for b in booksRatedList:\n",
    "        if booksRatedList[b] == maxRating:\n",
    "            tempSimi += similarityMatrix_book[bookIndex[predictBook]][bookIndex[b]]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        feat.append(0)\n",
    "    else:\n",
    "        feat.append(tempSimi / count)\n",
    "    \n",
    "    tempSimi = 0\n",
    "    count = 0\n",
    "    for b in booksRatedList:\n",
    "        if booksRatedList[b] == minRating:\n",
    "            tempSimi += similarityMatrix_book[bookIndex[predictBook]][bookIndex[b]]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        feat.append(0)\n",
    "    else:\n",
    "        feat.append(tempSimi / count)\n",
    "    \n",
    "    feat.append(avgSimilarity(predictUser, predictBook))\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6412777777777777\n",
      "0.7715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cui/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = [feature(d) for d in validationSet]\n",
    "y = [d[2] for d in validationSet]\n",
    "        \n",
    "X_train = X[:18000]\n",
    "y_train = y[:18000]\n",
    "X_test = X[18000:]\n",
    "y_test = y[18000:]\n",
    "        \n",
    "# model = linear_model.LogisticRegression(solver='lbfgs')\n",
    "# model = SVC(gamma='auto')\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# model.fit(X_train, y_train)\n",
    "model.fit(X, y)\n",
    "\n",
    "prediction_train = model.predict(X_train)\n",
    "predict_train = prediction_train == y_train\n",
    "accuracy_train = sum(predict_train) / len(predict_train)\n",
    "        \n",
    "prediction_test = model.predict(X_test)\n",
    "predict_test = prediction_test == y_test\n",
    "accuracy_test = sum(predict_test) / len(predict_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15657528 0.56116188 0.00199116 0.         0.         0.28027168]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"/home/cui/Projects/PycharmProjects/CSE-158/data/predictions_Read.txt\", 'w')\n",
    "\n",
    "for l in open(\"/home/cui/Projects/PycharmProjects/CSE-158/data/pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "        \n",
    "    u,b = l.strip().split('-')\n",
    "\n",
    "    predict = model.predict([feature([u, b])])\n",
    "    if predict == 1:\n",
    "        predictions.write(u + '-' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + b + \",0\\n\")\n",
    "        \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
