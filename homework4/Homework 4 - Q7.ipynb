{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/cui/Projects/PycharmProjects/CSE-158/data/train_Category.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(parseData(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training = [d['rating'] for d in dataset[:10000]]\n",
    "y_validation = [d['rating'] for d in dataset[10000:20000]]\n",
    "y_test = [d['rating'] for d in dataset[20000:30000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, targets):\n",
    "    return ((predictions - targets) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(ngrams, removePunctuation, tfidf, wordCounts):\n",
    "    punctuation = set(string.punctuation)\n",
    "    corpus = []\n",
    "    max_features = 20000\n",
    "    \n",
    "    if removePunctuation:\n",
    "        for d in dataset[:30000]:\n",
    "            text = d['review_text']\n",
    "            text = text.lower()\n",
    "            text = [c for c in text if not (c in punctuation)]\n",
    "            text = ''.join(text)\n",
    "            corpus.append(text)\n",
    "    else:\n",
    "        for d in dataset[:30000]:\n",
    "            tmp = d['review_text']\n",
    "            tmp = tmp.lower()\n",
    "            text = []\n",
    "            for c in tmp:\n",
    "                if c in punctuation:\n",
    "                    text.append(\" \")\n",
    "                    text.append(c)\n",
    "                    text.append(\" \")\n",
    "                else:\n",
    "                    text.append(c)\n",
    "            text = ''.join(text)\n",
    "            corpus.append(text)\n",
    "    \n",
    "    X = []\n",
    "    \n",
    "    # if parameter tfidf is True, using tf-idf vectorizer \n",
    "    if tfidf:\n",
    "        vec = TfidfVectorizer(ngram_range=(ngrams, ngrams), max_features=max_features)\n",
    "        X = vec.fit_transform(corpus)\n",
    "        X = X.toarray()\n",
    "    \n",
    "    # if parameter wordCounts is True, using count vectorizer\n",
    "    if wordCounts:\n",
    "        vec = CountVectorizer(ngram_range=(ngrams, ngrams), max_features=max_features)\n",
    "        X = vec.fit_transform(corpus)\n",
    "        X = X.toarray()\n",
    "    \n",
    "    X_training = X[:10000]\n",
    "    X_validation = X[10000:20000]\n",
    "    X_test = X[20000:30000]\n",
    "    \n",
    "    MSE_list = []\n",
    "    regularization = [0.01, 0.1, 1, 10, 100]\n",
    "    for r in regularization:\n",
    "        clf = linear_model.Ridge(r, fit_intercept=False)\n",
    "        clf.fit(X_training, y_training)\n",
    "        predictions = clf.predict(X_validation)\n",
    "        MSE_list.append((r, MSE(predictions, y_validation)))\n",
    "    \n",
    "        del clf\n",
    "        \n",
    "    return MSE_list, X_training, X_validation, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_testSet(MSE_list, X_training, X_validation, X_test):\n",
    "    r = min(MSE_list, key = lambda x:x[1])[0]\n",
    "\n",
    "    clf = linear_model.Ridge(r, fit_intercept=False)\n",
    "    clf.fit(X_training, y_training)\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    mse = round(MSE(predictions, y_test), 3)\n",
    "\n",
    "    print (\"The MSE of the test set is {:.3f}.\".format(mse))\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Unigrams & Removing punctuation & tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(1, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 4.231921387378723),\n",
       " (0.1, 2.530514873651722),\n",
       " (1, 1.98077786370894),\n",
       " (10, 2.26540381409375),\n",
       " (100, 3.3078669950698605)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 1.940.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Unigrams, remove punctuation and using tf-idf scores\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Unigrams & Removing punctuation & Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(1, True, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 100.56290076827047),\n",
       " (0.1, 54.292731348707385),\n",
       " (1, 22.805745018853557),\n",
       " (10, 10.85740713173832),\n",
       " (100, 7.388132286034386)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 7.116.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Unigrams, remove punctuation and using word counts\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unigrams & Preserving punctuation & tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(1, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 4.316604607819873),\n",
       " (0.1, 2.5358068742106763),\n",
       " (1, 1.9652322732523957),\n",
       " (10, 2.2433897060794266),\n",
       " (100, 3.2837694424099646)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 1.932.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Unigrams, preserve punctuation and using tf-idf scores\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Unigrams & Preserving punctuation & Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(1, False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 104.49586690530538),\n",
       " (0.1, 55.371576744287566),\n",
       " (1, 22.85794513506134),\n",
       " (10, 10.999730770757104),\n",
       " (100, 7.454292447464862)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 7.220.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Unigrams, preserve punctuation and using word counts\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Bigrams & Removing punctuation & tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(2, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 4.896307534843344),\n",
       " (0.1, 3.8012622958526743),\n",
       " (1, 3.0363105832826585),\n",
       " (10, 3.6130739101107743),\n",
       " (100, 6.587131482229626)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 2.889.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Bigrams, remove punctuation and using tf-idf scores\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bigrams & Removing punctuation & Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(2, True, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 61.28342585489422),\n",
       " (0.1, 33.54553164355451),\n",
       " (1, 19.63217253144386),\n",
       " (10, 10.230048234295362),\n",
       " (100, 7.455529943741971)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 7.127.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Bigrams, remove punctuation and using word counts\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Bigrams & Preserving punctuation & tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(2, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 4.863034411156802),\n",
       " (0.1, 3.758555054253984),\n",
       " (1, 3.002637063205719),\n",
       " (10, 3.5770305692365634),\n",
       " (100, 6.538793974606483)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 2.856.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Bigrams, preserve punctuation and using tf-idf scores\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Bigrams & Preserving punctuation & Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list, X_training, X_validation, X_test = function(2, False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 61.10764171329383),\n",
       " (0.1, 34.60855769334343),\n",
       " (1, 19.747199837154405),\n",
       " (10, 10.290871247045763),\n",
       " (100, 7.420340762065661)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the test set is 7.089.\n"
     ]
    }
   ],
   "source": [
    "performance.append((\"Bigrams, preserve punctuation and using word counts\", MSE_testSet(MSE_list, X_training, X_validation, X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams, remove punctuation and using tf-idf scores: 1.94\n",
      "Unigrams, remove punctuation and using word counts: 7.116\n",
      "Unigrams, preserve punctuation and using tf-idf scores: 1.932\n",
      "Unigrams, preserve punctuation and using word counts: 7.22\n",
      "Bigrams, remove punctuation and using tf-idf scores: 2.889\n",
      "Bigrams, remove punctuation and using word counts: 7.127\n",
      "Bigrams, preserve punctuation and using tf-idf scores: 2.856\n",
      "Bigrams, preserve punctuation and using word counts: 7.089\n",
      "The best performance on test set is using Unigrams, preserve punctuation and using tf-idf scores\n"
     ]
    }
   ],
   "source": [
    "for i in performance:\n",
    "    print(i[0] + \": \" + str(i[1]))\n",
    "\n",
    "print(\"The best performance on test set is using \" + min(performance, key = lambda x:x[1])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
